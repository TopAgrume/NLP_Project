{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8429595,"sourceType":"datasetVersion","datasetId":5019846}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nfrom transformers import GPT2LMHeadModel, GPT2Tokenizer, TextDataset, DataCollatorForLanguageModeling, Trainer, TrainingArguments\n\n# Assuming you already have a DataFrame with columns 'poem' and 'topic'\n# Load your DataFrame\ndf = pd.read_csv(\"/kaggle/input/poem-classification-dataset/data.csv\")\n\n# Save the poems to a text file, required for training\nwith open('poems.txt', 'w') as f:\n    for poem in df['poem']:\n        f.write(poem + '\\n\\n')\n\n# Load the tokenizer and model\nmodel_name = 'gpt2'\ntokenizer = GPT2Tokenizer.from_pretrained(model_name)\nmodel = GPT2LMHeadModel.from_pretrained(model_name)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-17T22:20:20.675690Z","iopub.execute_input":"2024-05-17T22:20:20.676556Z","iopub.status.idle":"2024-05-17T22:20:43.970977Z","shell.execute_reply.started":"2024-05-17T22:20:20.676509Z","shell.execute_reply":"2024-05-17T22:20:43.970057Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2024-05-17 22:20:30.265305: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-05-17 22:20:30.265413: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-05-17 22:20:30.391444: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"954c065ef1f44b71a46e7247d4b73422"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"48e81290cab44a14bf0558ec391a77bf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b10e740c3cc24f47b869388d3ff7a649"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"16b16d55c9d3405c82666e22b49bbe1c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"030fca193791457ea837a0770d53c60a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"03ef16a8d6e04e1284dbaa1cabe7560f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"957d892b7db446feac4ca54146996eac"}},"metadata":{}}]},{"cell_type":"code","source":"# Create a dataset from the poems text file\ndef load_dataset(file_path, tokenizer, block_size=128):\n    dataset = TextDataset(\n        tokenizer=tokenizer,\n        file_path=file_path,\n        block_size=block_size,\n    )\n    return dataset","metadata":{"execution":{"iopub.status.busy":"2024-05-17T22:20:43.972746Z","iopub.execute_input":"2024-05-17T22:20:43.973022Z","iopub.status.idle":"2024-05-17T22:20:43.977676Z","shell.execute_reply.started":"2024-05-17T22:20:43.972998Z","shell.execute_reply":"2024-05-17T22:20:43.976832Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"train_dataset = load_dataset('/kaggle/working/poems.txt', tokenizer)","metadata":{"execution":{"iopub.status.busy":"2024-05-17T22:20:43.978819Z","iopub.execute_input":"2024-05-17T22:20:43.979105Z","iopub.status.idle":"2024-05-17T22:21:25.931845Z","shell.execute_reply.started":"2024-05-17T22:20:43.979083Z","shell.execute_reply":"2024-05-17T22:21:25.930857Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/data/datasets/language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the ğŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"# Create a data collator\ndata_collator = DataCollatorForLanguageModeling(\n    tokenizer=tokenizer,\n    mlm=False,\n)","metadata":{"execution":{"iopub.status.busy":"2024-05-17T22:21:25.934300Z","iopub.execute_input":"2024-05-17T22:21:25.935034Z","iopub.status.idle":"2024-05-17T22:21:25.939279Z","shell.execute_reply.started":"2024-05-17T22:21:25.935000Z","shell.execute_reply":"2024-05-17T22:21:25.938356Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Set up training arguments\ntraining_args = TrainingArguments(\n    output_dir='./results',\n    overwrite_output_dir=True,\n    num_train_epochs=1,\n    per_device_train_batch_size=4,\n    save_steps=10_000,\n    save_total_limit=2,\n)","metadata":{"execution":{"iopub.status.busy":"2024-05-17T22:21:25.941156Z","iopub.execute_input":"2024-05-17T22:21:25.941525Z","iopub.status.idle":"2024-05-17T22:21:26.023112Z","shell.execute_reply.started":"2024-05-17T22:21:25.941492Z","shell.execute_reply":"2024-05-17T22:21:26.022281Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Create the Trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    data_collator=data_collator,\n    train_dataset=train_dataset,\n)","metadata":{"execution":{"iopub.status.busy":"2024-05-17T22:21:26.024195Z","iopub.execute_input":"2024-05-17T22:21:26.024479Z","iopub.status.idle":"2024-05-17T22:21:27.220383Z","shell.execute_reply.started":"2024-05-17T22:21:26.024456Z","shell.execute_reply":"2024-05-17T22:21:27.219647Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \ndataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"## Fine-tune the model\nimport os\nos.environ['WANDB_MODE'] = 'disabled'\n\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-05-17T22:45:23.494806Z","iopub.execute_input":"2024-05-17T22:45:23.495626Z","iopub.status.idle":"2024-05-17T23:00:23.209217Z","shell.execute_reply.started":"2024-05-17T22:45:23.495595Z","shell.execute_reply":"2024-05-17T23:00:23.208434Z"},"trusted":true},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='8892' max='8892' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [8892/8892 14:59, Epoch 1/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>4.040800</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>4.062100</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>4.047000</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>4.070900</td>\n    </tr>\n    <tr>\n      <td>2500</td>\n      <td>4.070800</td>\n    </tr>\n    <tr>\n      <td>3000</td>\n      <td>4.066300</td>\n    </tr>\n    <tr>\n      <td>3500</td>\n      <td>4.101100</td>\n    </tr>\n    <tr>\n      <td>4000</td>\n      <td>4.086500</td>\n    </tr>\n    <tr>\n      <td>4500</td>\n      <td>4.059300</td>\n    </tr>\n    <tr>\n      <td>5000</td>\n      <td>4.077800</td>\n    </tr>\n    <tr>\n      <td>5500</td>\n      <td>4.117900</td>\n    </tr>\n    <tr>\n      <td>6000</td>\n      <td>4.094500</td>\n    </tr>\n    <tr>\n      <td>6500</td>\n      <td>4.118600</td>\n    </tr>\n    <tr>\n      <td>7000</td>\n      <td>4.118500</td>\n    </tr>\n    <tr>\n      <td>7500</td>\n      <td>4.117700</td>\n    </tr>\n    <tr>\n      <td>8000</td>\n      <td>4.134800</td>\n    </tr>\n    <tr>\n      <td>8500</td>\n      <td>4.124100</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=8892, training_loss=4.089257367709387, metrics={'train_runtime': 899.2714, 'train_samples_per_second': 39.552, 'train_steps_per_second': 9.888, 'total_flos': 2323408748544000.0, 'train_loss': 4.089257367709387, 'epoch': 1.0})"},"metadata":{}}]},{"cell_type":"code","source":"trainer.save_model(\"./result_train2\")\ntokenizer.save_pretrained(\"./result_train2\")","metadata":{"execution":{"iopub.status.busy":"2024-05-17T23:00:23.210841Z","iopub.execute_input":"2024-05-17T23:00:23.211122Z","iopub.status.idle":"2024-05-17T23:00:24.387256Z","shell.execute_reply.started":"2024-05-17T23:00:23.211099Z","shell.execute_reply":"2024-05-17T23:00:24.386349Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"('./result_train2/tokenizer_config.json',\n './result_train2/special_tokens_map.json',\n './result_train2/vocab.json',\n './result_train2/merges.txt',\n './result_train2/added_tokens.json')"},"metadata":{}}]},{"cell_type":"code","source":"# Load the fine-tuned model for generation\nmodel = GPT2LMHeadModel.from_pretrained('/kaggle/working/result_train2')\ntokenizer = GPT2Tokenizer.from_pretrained(model_name)","metadata":{"execution":{"iopub.status.busy":"2024-05-17T23:00:24.388391Z","iopub.execute_input":"2024-05-17T23:00:24.388656Z","iopub.status.idle":"2024-05-17T23:00:24.956479Z","shell.execute_reply.started":"2024-05-17T23:00:24.388634Z","shell.execute_reply":"2024-05-17T23:00:24.955486Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# Function to generate poems from a prompt\ndef generate_poem(prompt, model, tokenizer, max_length=200, temperature=0.7):\n    inputs = tokenizer.encode(prompt, return_tensors='pt')\n    outputs = model.generate(inputs, max_length=max_length, temperature=temperature, num_return_sequences=1, num_beams=5, no_repeat_ngram_size=2)\n    return tokenizer.decode(outputs[0], skip_special_tokens=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-17T23:00:55.756642Z","iopub.execute_input":"2024-05-17T23:00:55.757265Z","iopub.status.idle":"2024-05-17T23:00:55.762469Z","shell.execute_reply.started":"2024-05-17T23:00:55.757236Z","shell.execute_reply":"2024-05-17T23:00:55.761573Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# Example usage\nprompt = \"Long live the king\"\ngenerated_poem = generate_poem(prompt, model, tokenizer)\nprint(generated_poem)","metadata":{"execution":{"iopub.status.busy":"2024-05-17T23:01:56.833428Z","iopub.execute_input":"2024-05-17T23:01:56.833801Z","iopub.status.idle":"2024-05-17T23:02:12.988049Z","shell.execute_reply.started":"2024-05-17T23:01:56.833774Z","shell.execute_reply":"2024-05-17T23:02:12.987064Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Long live the kingâ€™s blood,\nAnd the blood of his sons.\n\nThe king is dead, and the sons\nAre dead. The king was born\nIn the land of the dead;\nHe was the son of a king\nWho died in his own blood.\n\n\n\n\n(from â€œThe Song of Solomonâ€ by Robert Klee, translated from the Spanish by David S. Lewis, published by the University of California Press, 2001)\n\nÂ  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â â€œI have heard the voice of God, Â Â Â Â Â Â Â Â Â And I have seen the face of Heav'n.  Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â The Lord is in the midst of all things; Â Â Â Â Â Â Â Â Â Â Â Â He is the King of Israel, the Lord of hosts, The Lord and God of men; He is God and man; and he is good and wise; And he hath power and will. Â Â Â  And He hath the power\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}